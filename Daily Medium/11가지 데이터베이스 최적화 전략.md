written by Daniel Foo(CTO of moneyLion)

# 1. Indexing:
 WHERE 문을 사용할 때, 진가를 발휘한다. indexing은 말 그대로 데이터에 인덱스를 추가해서, 데이터에 대한 빠르고 간단한 lookup을 가능케 해준다. <u>SELECT문에 대한 속도도 빠르게 해주는 feature이기에, 분석이 많이 필요한 서비스에 적합하지만, write 같은 DML에 대해서는 더 많은 연산이 필요하기에 수정이나, 삭제가 많이 필요한 서비스에서는 적절치 않다.</u>

> <b>CREATE</b> INDEX idx_username <b>ON</b> users(username);


# 2. Normalization & Denormalization

## Normalization (정규화):
 데이터의 중복, 의존성, 변칙들을 줄이거나 제거해서 데이터를 정렬하는 과정을 Normalization이라고 한다. 큰 테이블을 작은 테이블로 쪼개면서, 데이터의 일관성을 유지한다. <u> 복잡한 쿼리를 야기할 수는 있다.</u>

 > CREATE TABLE customers (<BR>
    &nbsp;&nbsp;&nbsp;customer_id INT PRIMARY KEY,<BR>
    &nbsp;&nbsp;&nbsp;customer_name VARCHAR(100),<BR>
    &nbsp;&nbsp;&nbsp;address VARCHAR(255)<BR>
 );
 <br>
 <br>
> CREATE TABLE orders (<BR>
    &nbsp;&nbsp;&nbsp;order_id INT PRIMARY KEY,<BR>
    &nbsp;&nbsp;&nbsp;customer_id INT,<BR>
    &nbsp;&nbsp;&nbsp;order_date DATE,<BR>
    &nbsp;&nbsp;&nbsp;FOREIGN KEY (cusomer_id) REFERENCES customers(customer_id)<BR>
 ); 

## Denormalization (비정규화):
정규화 과정이 중복을 제거하는 작업이라면, 비정규화 작업은 절제된 중복을 허용함으로써 쿼리문의 성능을 높인다. 무거운 테이블 대상으로 쿼리를 실행한다면, 해당 테이블에 접근하는 쿼리문 입장에서는 방문 판매를 해야할 테이블의 수가 적은 것이 좋다.작업 효율이 좋게 돌아가야 하기 때문에 테이블을 정규화하기 보다는 비정규화 작업을 통해 쿼리문의 수를 줄인다. column을 추가하는 것 뿐만 아니라, 테이블을 합치는 것 또한 비정규화 작업이다.

> CREATE TABLE denomarlized_orders (<BR>
    &nbsp;&nbsp;&nbsp;order_id INT PRIMARY KEY,<BR>
    &nbsp;&nbsp;&nbsp;customer_id INT,<BR>
    &nbsp;&nbsp;&nbsp;customer_name VARCHAR(100),<BR>
    &nbsp;&nbsp;&nbsp;order_date DATE <br>
 ); 

 # 3. Query Optimization
 * <b>Optimize Queries</b>: 규칙적으로 사용하는 쿼리에 대해서 최적화하고, 분석하는 것 또한 DBMS의 성능을 높이는 테크닉이다. EXPLAIN 같은 명령어를 사용해서 쿼리 방향성에 대해서 조사해보고 영역을 향상시킬 수 있다.
 > EXPLAIN SELECT * FROM orders WHERE customer_id =123;

 * <b>무분별한 SELECT * 사용 금지!</b>: 필요한 컬럼에 대해서만 조회를 하는것이 좋다. 무분별하게 모든 컬럼을 가져오는 것은 적절치 않다. 뭐 당연한 얘기지만 select에 대한 조건을 적당히 조절함에 따라서 쿼리문 성능과 전송 기능이 향상된다.

 # 4. PARTITIONING
 * <b>Partition Table</b>: 기존의 테이블. 이 같이 테이블을 partition해서 쿼리문을 실행시키면 데이터베이스 엔진 관점에서, 더 작은 데이터 부분집합에 접근하는 점이 있기 때문에 더 빠른 쿼리문 실행과 높은 향상성을 가질 수 있다.

 > CREATE TABLE sales(
    &nbsp;&nbsp;&nbsp;sale_id INT PRIMARY KEY, <BR>
    &nbsp;&nbsp;&nbsp;sale_data DATE,<BR>
    &nbsp;&nbsp;&nbsp;amount DECIMAL(10,2)<BR>
 ) PARTITION BY RANGE (YEAR(sale_date)) (<BR>
    &nbsp;&nbsp;&nbsp;PARTITION p0 VALUES LESS THAN (1990),<BR>
    &nbsp;&nbsp;&nbsp;PARTITION p1 VALUES LESS THAN (2000),<BR>
    &nbsp;&nbsp;&nbsp;PARTITION p2 VALUES LESS THAN (2010),<BR>
    &nbsp;&nbsp;&nbsp;PARTITION p3 VALUES LESS THAN (2020),<BR>
    &nbsp;&nbsp;&nbsp;PARTITION p4 VALUES LESS THAN (MAXVALUE)<BR>
 ); <BR>

 <i> 다음 쿼리문을 보게 되면, 연도 컬럼에 걸려지는 데이터들을 불러오게 되는데, 데이터를 가져오는 과정을 연도별로 partition해서 가져오고 있다. 그렇기 때문에 위와 같이 정의된 테이블에다가 SELCET문을 쓴다면 미리 partition 되어 있는 데이터들을 가져오기 때문에 index를 설정한 것과 같이 훨씬 더 높은 효율성을 가지게 된다.</i>

 * <B>Partition Puruning</B>: 쿼리문을 실행할 떄 불필요한 partition을 포함시키지 않는 것 또한 중요하기 때문에, 모든 dataset을 select하는 거보다는 일부 partition만 가져와 select하는 것이 좋다. 

 > SELECT * FROM sales WHERE sales_date >= '2022-01-01' AND sale_date < '2023-01-01';

 # 5. Caching
 ### Query Caching:
  빈번하게 사용되는 쿼리문에 대해서, 캐싱 메커니즘을 설정하는 것 또한 퍼포먼스를 높이는 테크닉 중 하나다. 이전에 실행해 놓은 쿼리문에 대해서, 캐싱을 해놓은 결과값을 가져오기 때문에, 짧은 시간의 응답 시간을 가지는 쿼리문을 설정 할 수 있다.

 
> -- Pseudocode <br>
 DECLARE @cacheKey NVARCHAR(255) = 'query_cache_key';<BR>
 DECLARE @cachedResult NVARCHAR(MAX);<BR><BR>
 SET @cachedResult=REDIS.GET(@cacheKey); <br><br>
 IF @cachedResult IS NULL<br>
 BEGIN<br>
 &nbsp;&nbsp;&nbsp;-- Execute the query and store the result in the cache<BR>
 &nbsp;&nbsp;&nbsp;SET @cachedResult = EXECUTE_QUERY('SELECT * FROM large_table');<BR>
 &nbsp;&nbsp;&nbsp;REDIS.SET(@cacheKey,@cachedResult, EXPIRE_TIME );<BR>
 END<BR><BR>
-- Use @cachedResult for further processing

 ### Object Caching:
 빈번하게 사용되는 오브제긑나 데이터를 application layer에 캐싱함에 따라, 데이터베이스 쿼리문을 최소화 할 수 있다. <i>인메모리 캐싱 라이브러리나 프레임워크를 사용함으로써 구현이 가능하다. </i>

 > from django.core.chae import cache # django 프레임워크를 사용 <br><br>
 def get_user_data(user_id):<br>
  #try to fetch user data from cache<br>
  user_data=cache.get(f'user_{'user_id'})<br>
  <br>
  if(user_data) is None:<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# if not in cache, fetch from database<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;user_data=User.objects.get(id=user_id)<br>
  <br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;# Store the data in cache for future requests<br>
  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;cache.set(f'user_{user_id}',user_data, TIMEOUT)<br>
  return user_data


  # 6. Regular Maintenance:
  * <b>Updatae Staticstics</b>: Statistics에 대해서 지속적으로 업데이트 해주는 것도 중요한 사항이다. 지속적으로 statistics를 업데이트 해주어, 효율적이고 정확하게 쿼리문이 작동되도록 관리해야 한다.

  > --Update statistics for a table <br>
  UPDATE STATISTICS table_name;

  * <b>Data Archiving</b>: 오래된 데이터에 대해서, Archieve 하거나 삭제를 해야된다. 이 과정을 통해서 내부 저장소를 정리하고, 쿼리의 성능을 향상시킬 수 있다.(특히, 오래된 데이터들 중 양이 큰 데이터에서)

  > --Arhieve data older than a certain date <br>
  DELETE FROM historical_data WHERE date < '2020-01-01';


# 7. Hardware Optimization:
* <b>Optimize Server Configuration:</b>
workload와 하드웨어의 성능에 따라, 데이터베이스의 서버 세팅과 구성에 대해서 조정을 해야 한다. 이러한 조정에는 buffer size, cache 세팅, 연결에서의 한계가 포함되어야 한다.

> --Example: Increase the size of the query cache<BR>
SET GLOBAL query_cache_size =256M;

* <b>SSD 사용</b>
SSD를 사용하면 하드 드라이브보다 훨씬 더 빠른 성능을 보장할 수 있다.


# 8. Concurrency Control
### Isolation levels:
applications의 요구사항에 따라 접근권한을 설정하는 것 또한 데이터베이스 성능을 향상시키는 요인 중 하나다. 접근 권한은 다른 transaction에서부터 다른 transaction으로의 변경사항에 대한 가시성을 조정한다. 적정한 접근권한을 선택하는 것은 일관성과 성능 면에서 중요한 면이다.

> --set isolation level to READ COMMITTED
SET TRANSACTION ISOLATION LEVEL READ COMITTED;


# 9. Connection Pooling
### User Connection Pooling: 
데이터베이스 연결 시 기존에 연결했던 관계라면 연결을 재사용하는 것이 중요하다. 재사용에 대한 정의를 해주지 않는다면 연결할 때마다 overhead를 지속적으로 정의하면서 성능 면이나 데이터베이스 사용의 효율성 면에서 떨어지게 된다.

> HikariConfig config=new HikariConfig();<br>
config.setJdbcUrl("jdbc:mysql://localhost:3306/database");<br>
config.setUsername("username");<br>
config.setPasword("password");<br>
config.setMaximumPoolsize(10);<br><br>
HikariDataSource dataSource=new HikariDataSource(config);

# 10. Database DEsign:
### Efficient Schema Design: 
항상 데이터베이스를 디자인 할 때 성능을 고려하면서 디자인 하는 버릇을 들어야 한다. 적절한 데이터 타입, 적절한 constraints, 불필요한 관계에 대해서 정리하는 등의 습관을 들여야 한다. 많은 고려가 들어간 데이터베이스는 쿼리효율성이 크게 증가한다.

> CREATE TABLE products (
    product_id INT PRIMARY KEY,
    product_name VARCHAR(255),
    price DECIMAL(10,2),
    -- Additional columns as needed
)

# 11. Monitoring and Profiling:
### 정기적인 모니터링: 
ETL을 하던, 정기적인 배치 작업을 통해서 데이터를 옮기던, 해당 작업에 대해서 모니터링하는 프로세스를 갖추어야 한다. 클라우드 플랫폼을 통해서 해당 데이터 엔지니어링 작업이 이루어진다면, VM의 CPU 사용, 메모리 사용량, 쿼리 사용법 등의 데이터들을 활용해서 잠재적인 문제에 대해서 반응을 할 수 있어야 한다.

> SHOW STATUS LIKE 'CPU%';

### 쿼리 프로파일링
각 쿼리에 대해서 분석하고 어떤 기능을 하는지 정확히 파악해야 한다. 병목현상(bottleneck)이 발생했을 때, 해당 이해를 통해서 야기될 수 있는 문제점을 추리하면서 문제를 해결해야 하기 때문에, MYSQL Performance SChema 같은 디테일한 인사이트를 관찰 가능하다.

> -- Enable Performance Schema<br>
SET GLOBAL performance_schema= ON;<br>
--Profile a specific query <br>
SELECT * FROM orders WHERE customer_id=123;



















