# 빅데이터의 배경과 정착
> 분산 시스템에 의한 데이터 처리의 고속화

* 점점 데이터, API, 크게는 벌크 데이터까지 점차 서비스 내에서 오고 가는 데이터의 양이 RDB로는 감당하기 어려울 만큼, 현재 데이터가 쌓이는 속도는 비약적으로 증가했고, 이를 처리하려면 기존과는 다른 구조에 대해서 생각해볼 필요가 있다.

* Hadoop: 전공 수업을 들었을 때, 달달 외우기만 했는데 막상 현업에서 공부하면서 이 기술이 얼마나 data engineering에서 정말 중요한 프로그램인지 뼈저리게 깨닫았다. 간단하게 말하면, 엄청난 양의 데이터가 들어왔을 때, 하나의 클러스터 또는 컴퓨터, 서버가 감당하기 어려운 데이터가 들어 왔을 때, 이를 저장하기 위해 나누어서 데이터를 저장하고 분산되어서 저장된 데이터에 대해서 불러오거나 저장, 삭제할 때 이를 관리하기 위한 시스템으로 Hadoop이 이를 관리한다.

* NoSQL: RDB의 제약(유일성을 증빙하기 위한 key[PK, SK 등], 데이터 무결성[개체 무결성, 참조 무결성] 등 ) 등, 실제로 데이터가 많다보면, 여러가지 조건으로 결국에는 RDB에서 필요로 하는 조건은 너무나도 불필요한 조건이기 때문에, NOSQL은 어쩌면 데이터 엔지니어 영역에서는 필수적인 요건이다.

# 분산시스템의 비즈니스 이용 개척
* 전통적인 DW에서도 대량의 데이터를 처리할 수 있으며, 여러 방면에서 Hadoop보다도 우수하나, 확장이 어려웠기 때문에 가속적으로 늘어나는 데이터의 처리는 Hadoop에 맡기고, 비교적 작은 데이터, 또는 중요한 데이터만을 DW에 넣는 식으로 사용을 구분하게 되었다. (index를 줄이는 방식)

# 데이터 파이프라인 
> 테이블에서 테이블, 또는 테이블에서 다른 시스템, 또는 저장소에서 다른 저장소로 갈 때의 연결을 데이터 파이프라인이라고 한다. 하지만 여기서 고려해야 할 점은 <b>데이터를 보내는 목적성</b>이다. 예를 들어, RDB로 만든 호텔 예약 서비스에서 매일 회원들의 예약 정보를 오전 4시에 배치 받는 서비스가 있다고 해보자. 그렇다면, 데이터 엔지니어라고 가정한다면 RDB가 어떤 SQL로 정의되었고 서비스의 서버가 구현하는 로직에 맞게끔 데이터를 쿼리문이나 다른 방법을 사용해서 정제해서 보내주는 아키텍쳐를 설계하는 것이 데이터 엔지니어의 역할이다.

데이터 파이프라인에서의 데이터 흐름은 크게 2가지로 분류된다.
1. Batch Processing
2. Data Streaming
문자 그대로 Batch는 일정 시간에 스케줄된 로직에 따라 데이터를 일정 시간에 보내는 방식이곡, Data Streaming은 서바나 ,클라이언트 딴에서 데이터를 요청한다면 데이터를 보내주는 방식이다. 그렇기 때문에, 요청을 위한 신호가 별도로 정의되어야 하며, batch에 비해 고려해야 할 점이 헤더나, 실시간으로 보냈을 때, 테이블에서 허용할 수 있을 정도의 능력에 대해서 고려해보는 것까지 많은 생각이 필요로 하는 작업이다.

## Data Pipeline 아키텍쳐
크게 세가지로 구분되는데, 이는 다음과 같다.
1. Data Ingestion
여러 데이터 원천지로부터 데이터를 불러오는 과정을 말한다. 각 데이터 원천지는 각 회사의 컨벤션에 따라, publisher, provider, sender로 명명된다. 

2. Data Transformation
이전에 ingestion 파트에서 말했듯이 설계시기나, 설계자의 사정에 따라 여러 데이터 구조로부터 데이터를 가져와야 하기 때문에, 메시지 브로커를 사용하던, 데이터들을 쿼리문으로 <b>타겟이 되는 repositiry에 걸맞는 데이터로 전환되어야 한다.</b> 예를 들어, 테이블에서 가져오는 데이터가 CSV 파일이고, server가 워하는 데이터가 JSON 형식의 api라면 이를 전환해서 보내주어야 한다.


## Data Pipeline vs ETL pipeline
많이들 해깔리게 되는 개념이다. 처음에 Data dengineering 공부를 하기 전에 그룹사의 고객 데이터를 가져오는 작업을 데이터 파이프라인 설계 작업으로 착각했으나 실은 중계서버를 만들고 이를 처리하는 ETL 파이프라인을 만든것에 불과하다.

이를 헤깔리는 이유는 ETL은 data pipeline의 <i>>부분함수에 불과하다</i>. ETL은 말 그대로 데이터를 추출하고(extract), 변환하고(translate: 가끔은 정제), 보내준다(load)). 그렇기 떄문에, 모든 ETL 파이프라인은 이 세가지 형식을 공통적으로 가지고 있는 특징을 가지고 있다. 반면, data pipeline 중 일부는 예를 들어, Pub/sub의 개념에서 메시지 브로커를 지난다고 생각한다면 다음의 ETL 과정 뿐만 아니라, 다른 노드의 데이터 로드를 기다리기 위해서 큐에서 대기하는 과정을 위해서 index를 보내는 과정과 대기의 과정등이 추가된다.

또, ETL은 실시간 데이터 교환이 가능하지만, ETL은 batch에 한정되어 있고, Data Pipeline은 배치 뿐만 아니라 Data streaming까지 포함하는 개념을 가지고 있기 때문에 이 또한 종속 범위임을 확인할 수 있는 특징이다.

마지막으로, 데이터 파이프라인은 꼭 translation을 거치지 않아도 된다. 이전에 말했던 예처럼 몇몇 pub/sub 모델의 개념에서 본다면 pub은 데이터를 전송하는 과정만 있기 때문에 굳이 translation 과정을 파이프라인에 정의하지 않아도 된다.


